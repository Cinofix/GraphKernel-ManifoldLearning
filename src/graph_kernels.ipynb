{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read this article presenting a way to improve the disciminative power of graph kernels.\n",
    "\n",
    "**Choose one graph kernel among\n",
    "\n",
    "    Shortest-path Kernel\n",
    "    Graphlet Kernel\n",
    "    Random Walk Kernel\n",
    "    Weisfeiler-Lehman Kernel\n",
    "\n",
    "**Choose one manifold learning technique among\n",
    "\n",
    "    Isomap\n",
    "    Diffusion Maps\n",
    "    Laplacian Eigenmaps\n",
    "    Local Linear Embedding\n",
    "\n",
    "**Compare the performance of an SVM trained on the given kernel, with or without the manifold learning step, on the following datasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T08:25:58.030643Z",
     "start_time": "2018-10-03T08:25:57.699617Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "def fit_n_components(D, Y, manifold_learning, n_neighbors = 14, n_iteration = 20):\n",
    "    max_acc = 0.0\n",
    "    max_idx = 1\n",
    "    clf = svm.SVC(kernel=\"linear\", C = 1.0)\n",
    "    for i in range(2,n_iteration):\n",
    "        ml_prj_D = manifold_learning(n_neighbors, i).fit_transform(D)\n",
    "        scores_ln = cross_val_score(clf, ml_prj_D, Y, cv = 10, n_jobs= 8)\n",
    "        #print(\"I:\"+ str(i)+ \" \"+str(np.mean(scores_ln)))\n",
    "        if np.mean(scores_ln) > max_acc:\n",
    "            max_acc = np.mean(scores_ln)\n",
    "            max_idx = i\n",
    "    return max_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weisfeiler Lehman Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T08:25:58.051542Z",
     "start_time": "2018-10-03T08:25:58.032296Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class WeisfeilerLehmanKernel():\n",
    "    n_labels = 0\n",
    "    compressed_labels = {} #{ hash_key: [hash]}\n",
    "\n",
    "    def get_nodes_degree(self, graph):\n",
    "        v = graph.shape[0]\n",
    "        ones = np.ones((v,1))\n",
    "        return np.dot(graph, ones)\n",
    "    \n",
    "    def get_graphs_labels(self, graphs):\n",
    "        n = len(graphs)\n",
    "        graphs_labels = []\n",
    "        for G in graphs:\n",
    "            graphs_labels.append(self.get_nodes_degree(G))\n",
    "        return graphs_labels\n",
    "    \n",
    "    def labels_to_feature_vectors(self, graphs_degree_labels):\n",
    "        n = len(graphs_degree_labels)\n",
    "        size = int(np.max(np.concatenate(graphs_degree_labels)))\n",
    "        degree_component = np.zeros((n, size))\n",
    "        for i in range(len(graphs_degree_labels)):\n",
    "            for j in graphs_degree_labels[i]:\n",
    "                degree_component[i,int(j)-1] += 1\n",
    "        return degree_component\n",
    "\n",
    "    \n",
    "    def get_multiset_label(self, graph, graph_labels):\n",
    "        n = graph.shape[0]\n",
    "        graphs_labels = np.empty((n,), dtype = np.object)\n",
    "        \n",
    "        for v in range(n):\n",
    "            np.insert(np.nonzero(graph[v]), 0, values = v)\n",
    "            neighbors = np.insert(np.nonzero(graph[v]), 0, v)\n",
    "            multiset = [graph_labels[neighbor][0] for neighbor in neighbors]\n",
    "            multiset[1:] = np.sort(multiset[1:])\n",
    "            graphs_labels[v] = np.array(multiset)\n",
    "        return graphs_labels\n",
    "    \n",
    "    def get_multisets_labels(self, graphs, graphs_labels):\n",
    "        n = len(graphs)\n",
    "        multi_labels = np.empty((n,), dtype = np.object)\n",
    "        for idx in range(n):\n",
    "            multi_labels[idx] = self.get_multiset_label(graphs[idx], graphs_labels[idx])\n",
    "        return multi_labels\n",
    "    \n",
    "    def labels_compression(self, multisets_graph_labels):\n",
    "        graph_cmpr_labels = {} #{hash_key: [hash, #occurences]}\n",
    "\n",
    "        for m_labels in multisets_graph_labels:\n",
    "            str_label = str(m_labels)\n",
    "            if str_label not in self.compressed_labels:\n",
    "                self.compressed_labels.update({str_label: self.n_labels})\n",
    "                self.n_labels += 1\n",
    "            \n",
    "            label_hash = self.compressed_labels[str_label]\n",
    "            \n",
    "            if str_label not in graph_cmpr_labels:\n",
    "                graph_cmpr_labels.update({str_label: [label_hash, 1]})\n",
    "            else:\n",
    "                value = graph_cmpr_labels[str_label]\n",
    "                value[1]+= 1;\n",
    "                graph_cmpr_labels.update({str_label: value})\n",
    "        return graph_cmpr_labels\n",
    "    \n",
    "    def relabelling_graphs(self, new_labels, graphs_labels):\n",
    "        n_graphs = len(new_labels)\n",
    "        for i in range(n_graphs):\n",
    "            cmpr_labels = self.labels_compression(new_labels[i])\n",
    "            n = new_labels[i].shape[0]\n",
    "            \n",
    "            for v in range(n):\n",
    "                node_labels = new_labels[i][v]\n",
    "                f_node_labels = cmpr_labels[str(node_labels)][0]\n",
    "                graphs_labels[i][v] = f_node_labels        \n",
    "                \n",
    "    def wl_test_graph_isomorphism(self, graphs, h):\n",
    "        n = len(graphs)\n",
    "        #features = np.empty((n,1), dtype = np.object)\n",
    "        graphs_labels = self.get_graphs_labels(graphs)\n",
    "        degree_component = self.labels_to_feature_vectors(graphs_labels)\n",
    "        for i in range(h):\n",
    "            self.compressed_labels = {}\n",
    "            self.n_labels = 0\n",
    "            new_labels = self.get_multisets_labels(graphs, graphs_labels)\n",
    "            self.relabelling_graphs(new_labels, graphs_labels)\n",
    "            #print(\"h: \",str(i))\n",
    "        return np.array(graphs_labels), degree_component\n",
    "    \n",
    "    def extract_features_vectors(self, wl):\n",
    "        n = wl.shape[0]\n",
    "        features = np.zeros((n, self.n_labels))\n",
    "        for i in range(n):\n",
    "            for label in wl[i]:\n",
    "                features[i,int(label)]+= 1\n",
    "        return features\n",
    "    \n",
    "    def normalize(self,X):\n",
    "        norms = np.sqrt((X ** 2).sum(axis=1, keepdims=True))\n",
    "        XX = X / norms\n",
    "        return XX\n",
    "    \n",
    "    def eval_similarities(self, graphs, h):\n",
    "        self.compressed_labels = {}\n",
    "        self.n_labels = 0\n",
    "        WL, degree_component = self.wl_test_graph_isomorphism(graphs, h)\n",
    "        X = self.extract_features_vectors(WL)\n",
    "        X = np.concatenate((degree_component, X), axis = 1)\n",
    "        XX = self.normalize(X)\n",
    "        return np.dot(XX, XX.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest Path Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T08:25:58.062114Z",
     "start_time": "2018-10-03T08:25:58.053058Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "class KernelExecutor(Thread):\n",
    "    \n",
    "    def __init__(self, kernel, K, graphs, i):\n",
    "        Thread.__init__(self)\n",
    "        self.kernel_similarity = kernel\n",
    "        self.k_matrix = K\n",
    "        self.am_graphs = graphs\n",
    "        self.idx = i\n",
    "        self.v = len(self.am_graphs)\n",
    "        \n",
    "    def run(self):\n",
    "        for j in range(self.v):\n",
    "            self.k_matrix[self.idx,j] = self.kernel_similarity(self.am_graphs[self.idx], self.am_graphs[j])     \n",
    "            \n",
    "class FWExecutor(Thread):\n",
    "    \n",
    "    def __init__(self, graph_, shortest_path_method_, out_, idx_):\n",
    "        Thread.__init__(self)\n",
    "        self.graph = graph_\n",
    "        self.shortest_path_method = shortest_path_method_\n",
    "        self.out = out_\n",
    "        self.idx = idx_\n",
    "        \n",
    "    def run(self):\n",
    "        self.out[self.idx] = self.shortest_path_method(self.graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T08:25:58.076208Z",
     "start_time": "2018-10-03T08:25:58.063530Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "class ShortestPathKernel():\n",
    "\n",
    "    def initialize_paths(self, G):\n",
    "        INF_ = float('inf')\n",
    "        v = G.shape[0]\n",
    "        dist = G\n",
    "        dist[dist == 0] = INF_\n",
    "        np.fill_diagonal(dist, 0)\n",
    "        return dist\n",
    "    \n",
    "    def compute_FW_full(self, G):\n",
    "        G = G.astype(np.float)\n",
    "        dist = self.initialize_paths(G)\n",
    "        v = G.shape[0]\n",
    "        for k in range(v):\n",
    "            for i in range(v):\n",
    "                for j in range(v):\n",
    "                    dist[i,j] = min(dist[i,j], dist[i,k] + dist[k,j])\n",
    "        return dist\n",
    "    \n",
    "    def compute_FW(self, G):\n",
    "        G = G.astype(np.float)\n",
    "        dist = self.initialize_paths(G)\n",
    "        v = G.shape[0]\n",
    "        h = int(v/2)\n",
    "        for k in range(v):\n",
    "            for i in range(v):\n",
    "                for j in range(i,v):\n",
    "                    dist[i,j]= dist[j,i] = min(dist[i,j], dist[i,k] + dist[k,j])\n",
    "        return dist\n",
    "    \n",
    "    def compute_shortest_paths(self, graphs):\n",
    "        SP = []\n",
    "        i = 0\n",
    "        for adj_m in graphs:\n",
    "            SP.append(self.compute_FW(adj_m))\n",
    "            i+= 1\n",
    "        return SP\n",
    "\n",
    "    def compute_multi_shortest_paths(self, graphs):\n",
    "        v = len(graphs)\n",
    "        SP = np.empty((v,), dtype = np.object)\n",
    "        THREAD_FOR_TIME = 6\n",
    "  \n",
    "        for i in range(0,v,THREAD_FOR_TIME):\n",
    "            thr = []\n",
    "            NTHREAD = np.minimum(v-i,THREAD_FOR_TIME)\n",
    "            for j in range(NTHREAD):\n",
    "                ex = FWExecutor(graphs[i+j],self.compute_FW, SP, i+j)\n",
    "                thr.append(ex)\n",
    "                ex.start()\n",
    "            for j in range(NTHREAD):\n",
    "                thr[j].join()\n",
    "        return SP\n",
    "    \n",
    "    def extract_freq_vector(self, S, delta):\n",
    "        F = np.empty([delta+1, 1])\n",
    "        for i in range(delta+1):\n",
    "            F[i] = np.sum(S == i)\n",
    "        return F/norm(F)\n",
    "    \n",
    "    # similarity between frequency of paths\n",
    "    def k_delta(self, SP1, SP2):\n",
    "        delta = int(np.maximum(np.max(SP1), np.max(SP2)))\n",
    "\n",
    "        F1 = self.extract_freq_vector(SP1, delta)\n",
    "        F2 = self.extract_freq_vector(SP2, delta)\n",
    "        return  np.dot(np.transpose(F1), F2)[0]#, F1, F2\n",
    "    \n",
    "    # similarity between paths weights\n",
    "    def k_path_weigth(self, SP1, SP2):\n",
    "        v1 = SP1.shape[0]\n",
    "        v2 = SP2.shape[0]\n",
    "        max_size = np.maximum(v1,v2)+1\n",
    "        \n",
    "        S1_l = np.sum(SP1, axis = 1)\n",
    "        S2_l = np.sum(SP2, axis = 1)\n",
    "        \n",
    "        WS1_rows = np.concatenate([S1_l, np.zeros(max_size - v1)])# pad with zeros\n",
    "        WS2_rows = np.concatenate([S2_l, np.zeros(max_size - v2)]) # pad with zeros\n",
    "        return np.dot(WS1_rows, np.transpose(WS2_rows))/(norm(WS1_rows)*norm(WS2_rows))\n",
    "            \n",
    "    def kernel_similarity(self, SP1, SP2):\n",
    "        return self.k_delta(SP1, SP2)\n",
    "    \n",
    "    def eval_similarities(self, SP_graphs):\n",
    "        n = len(SP_graphs)\n",
    "        K = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                K[i,j] = self.kernel_similarity(SP_graphs[i], SP_graphs[j])\n",
    "        return K\n",
    "\n",
    "    def threads_eval_similarities(self, graphs):\n",
    "        n = len(graphs)\n",
    "        K = np.zeros((n, n))\n",
    "        THREAD_FOR_TIME = 2\n",
    "        for i in range(0, n, THREAD_FOR_TIME):\n",
    "            thr = []\n",
    "            for j in range(THREAD_FOR_TIME):\n",
    "                ex = KernelExecutor(self.kernel_similarity, K, graphs, i+j)\n",
    "                thr.append(ex)\n",
    "                ex.start()\n",
    "                \n",
    "            for j in range(THREAD_FOR_TIME):\n",
    "                thr[j].join()\n",
    "        return K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
